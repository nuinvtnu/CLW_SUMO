{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678},"id":"JE3Qk4bESM9_","executionInfo":{"status":"ok","timestamp":1752340965354,"user_tz":-420,"elapsed":15257,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}},"outputId":"9128c8ff-fc22-4bfd-fc0f-f2801b6015cb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Collecting numpy<2.0,>=1.18.5 (from gensim)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n","  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n","Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.15.3\n","    Uninstalling scipy-1.15.3:\n","      Successfully uninstalled scipy-1.15.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"3f893cdd7522419094bfeee44ddb86ab"}},"metadata":{}}]},{"cell_type":"code","source":["pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQwCL-PhSPpb","executionInfo":{"status":"ok","timestamp":1752341010690,"user_tz":-420,"elapsed":3772,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}},"outputId":"9cba33e2-8b46-4e66-bbc4-4189aa829a6e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"]}]},{"cell_type":"code","source":["# Load library\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, matthews_corrcoef, roc_curve, auc\n","import pickle\n","from keras.models import load_model\n","import pandas as pd\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","import pickle as pk\n","from nltk.tokenize import word_tokenize\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n","\n","from keras.layers import TextVectorization\n","from keras.utils import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Flatten, Conv1D, MaxPooling1D\n","from keras.utils import to_categorical\n","import re\n","from __future__ import print_function\n","\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import model_from_json\n","from keras import backend as K\n","from __future__ import print_function\n","import _pickle as cPickle\n","\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import LSTM, GRU, SimpleRNN\n","from keras.layers import Convolution1D, MaxPooling1D, Dense, Dropout, Activation\n","\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","from sklearn.model_selection import StratifiedKFold\n","from keras.models import model_from_json\n","from keras.models import load_model\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","\n","import random\n","from gensim.models import Word2Vec\n","from gensim.models.word2vec import LineSentence"],"metadata":{"id":"3hRQxBjRpzbt","executionInfo":{"status":"ok","timestamp":1752341020966,"user_tz":-420,"elapsed":6,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def twoTupleDic():\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        for j in AA_list_sort:\n","          for jj in AA_list_sort:\n","            AA_dict[i+j+jj] = numm\n","        AA_dict[i] = numm\n","        numm += 1\n","    return AA_dict"],"metadata":{"id":"v-3UIRNd8M-j","executionInfo":{"status":"ok","timestamp":1752341023482,"user_tz":-420,"elapsed":46,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def ProSentence(pro, K):\n","\tsentence = \"\"\n","\tlength = len(pro)\n","\tfor i in range(length - K + 1):\n","\t\tsentence += pro[i: i + K] + \" \"\n","    #delete extra space\n","\tsentence = sentence[0 : len(sentence) - 1]\n","\treturn sentence"],"metadata":{"id":"ssybE7NBVXJt","executionInfo":{"status":"ok","timestamp":1752341025004,"user_tz":-420,"elapsed":3,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Df1kA7PDR_8x","executionInfo":{"status":"ok","timestamp":1752341048535,"user_tz":-420,"elapsed":22874,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}},"outputId":"9ad12786-c6f0-4f5b-baf6-1716b97fe51f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/CLW_SUMO/Data/\"\n","path_model = \"/content/drive/MyDrive/CLW_SUMO/Model/\"\n","path_result = \"/content/drive/MyDrive/CLW_SUMO/Result/\"\n"],"metadata":{"id":"rf6pznQnxpdl","executionInfo":{"status":"ok","timestamp":1752341061865,"user_tz":-420,"elapsed":5,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Load Traindata\n","import pandas as pd\n","file_train = \"Train_Sumo.csv\"\n","df_train =pd.read_csv(path+file_train)\n","k =3\n","texts_train =[] #PTMsequend kmer\n","for i in df_train['Sequence']:\n","  temp = ProSentence(i,k) # Biểu diễn dữ liệu đầu vào thành token Kmer\n","  texts_train.append(temp)\n","df_train['k_mer'] =texts_train\n","df_train\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"m5dFD4dp8FEk","outputId":"65033960-8ed6-4802-a249-a609079474ce","executionInfo":{"status":"ok","timestamp":1752341064811,"user_tz":-420,"elapsed":2110,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}}},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Protein     Sequence  Label                                k_mer\n","0      Q96GD4  ALKVLFKSQIE      1  ALK LKV KVL VLF LFK FKS KSQ SQI QIE\n","1      Q9NPH2  RPGPSLKRVGP      1  RPG PGP GPS PSL SLK LKR KRV RVG VGP\n","2      Q9GZR7  GKWKEVKIDPN      1  GKW KWK WKE KEV EVK VKI KID IDP DPN\n","3      Q149N8  HTRQDVKQDAL      1  HTR TRQ RQD QDV DVK VKQ KQD QDA DAL\n","4      P11474  RCLPGHKEEED      1  RCL CLP LPG PGH GHK HKE KEE EEE EED\n","...       ...          ...    ...                                  ...\n","14947  P62851  MPPKDDKKKKD      0  MPP PPK PKD KDD DDK DKK KKK KKK KKD\n","14948  Q8IYM0  RDPKGKKRFIL      0  RDP DPK PKG KGK GKK KKR KRF RFI FIL\n","14949  Q8NC96  EMDARPKLDLG      0  EMD MDA DAR ARP RPK PKL KLD LDL DLG\n","14950  S4R3E2  KADPGVKSECL      0  KAD ADP DPG PGV GVK VKS KSE SEC ECL\n","14951  O14529  QKFLLEKPSLL      0  QKF KFL FLL LLE LEK EKP KPS PSL SLL\n","\n","[14952 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-c4b79ea3-4e55-4fbb-bd7e-a330d9c92084\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Protein</th>\n","      <th>Sequence</th>\n","      <th>Label</th>\n","      <th>k_mer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q96GD4</td>\n","      <td>ALKVLFKSQIE</td>\n","      <td>1</td>\n","      <td>ALK LKV KVL VLF LFK FKS KSQ SQI QIE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Q9NPH2</td>\n","      <td>RPGPSLKRVGP</td>\n","      <td>1</td>\n","      <td>RPG PGP GPS PSL SLK LKR KRV RVG VGP</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Q9GZR7</td>\n","      <td>GKWKEVKIDPN</td>\n","      <td>1</td>\n","      <td>GKW KWK WKE KEV EVK VKI KID IDP DPN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Q149N8</td>\n","      <td>HTRQDVKQDAL</td>\n","      <td>1</td>\n","      <td>HTR TRQ RQD QDV DVK VKQ KQD QDA DAL</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>P11474</td>\n","      <td>RCLPGHKEEED</td>\n","      <td>1</td>\n","      <td>RCL CLP LPG PGH GHK HKE KEE EEE EED</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>14947</th>\n","      <td>P62851</td>\n","      <td>MPPKDDKKKKD</td>\n","      <td>0</td>\n","      <td>MPP PPK PKD KDD DDK DKK KKK KKK KKD</td>\n","    </tr>\n","    <tr>\n","      <th>14948</th>\n","      <td>Q8IYM0</td>\n","      <td>RDPKGKKRFIL</td>\n","      <td>0</td>\n","      <td>RDP DPK PKG KGK GKK KKR KRF RFI FIL</td>\n","    </tr>\n","    <tr>\n","      <th>14949</th>\n","      <td>Q8NC96</td>\n","      <td>EMDARPKLDLG</td>\n","      <td>0</td>\n","      <td>EMD MDA DAR ARP RPK PKL KLD LDL DLG</td>\n","    </tr>\n","    <tr>\n","      <th>14950</th>\n","      <td>S4R3E2</td>\n","      <td>KADPGVKSECL</td>\n","      <td>0</td>\n","      <td>KAD ADP DPG PGV GVK VKS KSE SEC ECL</td>\n","    </tr>\n","    <tr>\n","      <th>14951</th>\n","      <td>O14529</td>\n","      <td>QKFLLEKPSLL</td>\n","      <td>0</td>\n","      <td>QKF KFL FLL LLE LEK EKP KPS PSL SLL</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>14952 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","      \n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4b79ea3-4e55-4fbb-bd7e-a330d9c92084')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","      \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","    \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c4b79ea3-4e55-4fbb-bd7e-a330d9c92084 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c4b79ea3-4e55-4fbb-bd7e-a330d9c92084');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","  \n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Tokenizer train data input Word2vec\n","data_token = []\n","for i in df_train['k_mer']:\n","   data_token.append(i.split())\n","print(data_token[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDBq_G51-KQo","outputId":"45dfe0de-ff91-49e9-c1ff-e8d0e7580cf3","executionInfo":{"status":"ok","timestamp":1752341068452,"user_tz":-420,"elapsed":8,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[['ALK', 'LKV', 'KVL', 'VLF', 'LFK', 'FKS', 'KSQ', 'SQI', 'QIE'], ['RPG', 'PGP', 'GPS', 'PSL', 'SLK', 'LKR', 'KRV', 'RVG', 'VGP']]\n"]}]},{"cell_type":"code","source":["# Len of the K_mer[1]\n","len(data_token[1])\n","MAX_SEQUENCE_LENGTH = len(data_token[1])\n","print(MAX_SEQUENCE_LENGTH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tlS_SzE2zJay","outputId":"96120e0a-b1c7-42a5-ca75-68d1b7f5100f","executionInfo":{"status":"ok","timestamp":1752341069856,"user_tz":-420,"elapsed":10,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n"]}]},{"cell_type":"code","source":["# Build Word2vec on train data\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from gensim.models import Word2Vec\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import numpy as np\n","import pickle as cPickle\n","import pandas as pd\n","word_index1 = twoTupleDic() # Tham chiếu texts thành word_index1  trong bộ từ điển\n","sequences = []\n","for each in texts_train:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    sequences.append(each_index_list)\n","\n","data_sequence = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","data_sequence\n","tokenizer = Tokenizer(num_words=None) # MAX_NB_WORDS\n","tokenizer.fit_on_texts(texts_train)\n","tokenizer.texts_to_sequences(texts_train) #num_words\n","word_index2 = tokenizer.word_index\n","\n","#word2vec\n","EMBEDDING_DIM = 300\n","name_model_w2vec =\"word2vec.model\"\n","w2v_model = Word2Vec(sentences=data_token , vector_size = EMBEDDING_DIM, window=5, min_count=1,sg=0)\n","w2v_model.train(data_token , total_examples=len(texts_train), epochs=10)\n","w2v_model.save(path+name_model_w2vec)\n","Word2VecModel = Word2Vec.load(path_model+name_model_w2vec)"],"metadata":{"id":"g9UFQYkj-Dxy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752341108025,"user_tz":-420,"elapsed":2718,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}},"outputId":"d0a5ed74-1414-4d69-9ff1-832c7f280607"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"]}]},{"cell_type":"code","source":["embedding_matrix = np.zeros((len(word_index1)+1, EMBEDDING_DIM))\n","for word, i in word_index1.items():\n","    word_lower = word.lower()\n","    if word_lower in Word2VecModel.wv:\n","        embedding_vector = Word2VecModel.wv[word_lower]\n","    else:\n","        # Gán vector ngẫu nhiên nếu từ không có trong vocab\n","        embedding_vector = np.random.normal(scale=0.6, size=(EMBEDDING_DIM,))\n","    embedding_matrix[i] = embedding_vector"],"metadata":{"id":"TBslCaO4rZ7w","executionInfo":{"status":"ok","timestamp":1752341261063,"user_tz":-420,"elapsed":102,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X = data_sequence\n","y = np.array(df_train['Label'])\n"],"metadata":{"id":"z4JHeJMK-Sew","executionInfo":{"status":"ok","timestamp":1752341286076,"user_tz":-420,"elapsed":15,"user":{"displayName":"Trần Xuân","userId":"05074640538518103342"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","from keras.models import Model\n","from keras.layers import Input, Embedding, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Dense, concatenate\n","\n","# --- Cấu hình ---\n","nb_epoch = 100\n","nb_filter = 128        # sửa từ nb_filte\n","k = 10\n","batch_size = 32\n","kf = KFold(n_splits=k, shuffle=True, random_state=42)\n","\n","# --- Biến lưu kết quả ---\n","fold_results = []\n","all_metrics = []\n","confusion_matrices = []\n","all_auc_scores = []\n","best_auc = 0\n","best_model = None\n","\n","plt.figure(figsize=(8, 6))\n","\n","for fold, (train_index, test_index) in enumerate(kf.split(X)):\n","    print(f\"Training on Fold {fold+1}/{k}...\")\n","\n","    X_train, X_test = X[train_index], X[test_index]\n","    Y_train, Y_test = y[train_index], y[test_index]\n","\n","    input_layer = Input(shape=(MAX_SEQUENCE_LENGTH,))\n","\n","    # Nhánh CNN\n","    cnn_branch = Embedding(input_dim=len(embedding_matrix),\n","                           output_dim=EMBEDDING_DIM,\n","                           weights=[embedding_matrix],\n","                           input_length=MAX_SEQUENCE_LENGTH,\n","                           trainable=False)(input_layer)\n","    cnn_branch = Conv1D(filters=nb_filter, kernel_size=3, activation='relu',padding='same')(cnn_branch)\n","    cnn_branch = MaxPooling1D(pool_size=2)(cnn_branch)\n","    cnn_branch = Dropout(0.3)(cnn_branch)\n","    cnn_branch = Conv1D(filters=nb_filter, kernel_size=3, activation='relu',padding='same')(cnn_branch)\n","    cnn_branch = MaxPooling1D(pool_size=2)(cnn_branch)\n","    cnn_branch = Flatten()(cnn_branch)\n","\n","    # Nhánh LSTM\n","    lstm_branch = Embedding(input_dim=len(embedding_matrix),\n","                            output_dim=EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            input_length=MAX_SEQUENCE_LENGTH,\n","                            trainable=False)(input_layer)\n","    lstm_branch = Dropout(0.4)(lstm_branch)\n","    lstm_branch = LSTM(units=128, dropout=0.2, recurrent_dropout=0.2)(lstm_branch)\n","    lstm_branch = Flatten()(lstm_branch)\n","\n","    # Kết hợp\n","    merged = concatenate([cnn_branch, lstm_branch])\n","    z = Dense(64, activation='relu')(merged)\n","    z = Dense(1, activation='sigmoid')(z)\n","\n","    model = Model(inputs=input_layer, outputs=z)\n","\n","    model.compile(optimizer='adam',\n","                  loss='binary_crossentropy',  # Sửa lại phù hợp bài toán nhị phân\n","                  metrics=['accuracy'])\n","\n","    model.fit(X_train, Y_train,\n","              epochs=nb_epoch,\n","              batch_size=batch_size,\n","              validation_data=(X_test, Y_test),\n","              shuffle=True,\n","              verbose=0)\n","\n","    # Đánh giá\n","    results = model.evaluate(X_test, Y_test, verbose=0)\n","    all_metrics.append(results)\n","\n","    # Dự đoán\n","    y_pred_probs = model.predict(X_test)\n","    y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n","    y_true_classes = Y_test.flatten()\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(y_true_classes, y_pred_classes)\n","    tn, fp, fn, tp = cm.ravel()\n","    confusion_matrices.append({\"Fold\": fold + 1, \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn})\n","\n","    print(f\"Fold {fold + 1} - TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n","\n","    # ROC-AUC\n","    fpr, tpr, _ = roc_curve(y_true_classes, y_pred_probs)\n","    auc_score = auc(fpr, tpr)\n","    all_auc_scores.append({\"Fold\": fold + 1, \"AUC\": auc_score})\n","    plt.plot(fpr, tpr, label=f\"Fold {fold + 1} (AUC = {auc_score:.4f})\")\n","\n","    # Lưu mô hình tốt nhất\n","    if auc_score > best_auc:\n","        best_auc = auc_score\n","        best_model = model\n","\n","# Lưu mô hình tốt nhất\n","if best_model:\n","    best_model.save(path_model + \"CLW_SUMO.h5\")\n","    print(\"\\nBest model saved as 'CLW_SUMO.h5'\")\n","\n","# Trung bình kết quả\n","avg_metrics = np.mean(all_metrics, axis=0)\n","avg_auc = np.mean([auc_info[\"AUC\"] for auc_info in all_auc_scores])\n","\n","print(f\"\\nAverage Metrics over {k}-Fold Cross Validation:\")\n","for metric_name, avg_metric in zip(model.metrics_names, avg_metrics):\n","    print(f\"{metric_name}: {avg_metric:.4f}\")\n","print(f\"\\nAverage AUC-ROC: {avg_auc:.4f}\")\n","\n","# Lưu Excel\n","df_confusion = pd.DataFrame(confusion_matrices)\n","df_auc = pd.DataFrame(all_auc_scores)\n","with pd.ExcelWriter(path_result + \"cv_CLW_SUMO.xlsx\") as writer:\n","    df_confusion.to_excel(writer, sheet_name=\"Confusion Matrix\", index=False)\n","    df_auc.to_excel(writer, sheet_name=\"AUC Scores\", index=False)\n","print(\"\\nResults saved to 'cv_CLW_SUMO.xlsx'\")\n","\n","# Vẽ đường cong tổng hợp\n","plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.5)')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title(f'ROC Curve CLW_SUMO (Avg AUC = {avg_auc:.4f})')\n","plt.legend()\n","plt.grid()\n","plt.show()\n"],"metadata":{"id":"MSl78bhpnw_R"},"execution_count":null,"outputs":[]}]}